{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIHwXss357nskrZ8Jvi5XD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09dc734eaec44468a4b239c1da5d7754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d31e3f1b97b48309264d4eb82c7099d",
              "IPY_MODEL_c1a78bb2373b432b8bcd4a9378b88f7e",
              "IPY_MODEL_243d80deab9749768c4b68c9891488cd"
            ],
            "layout": "IPY_MODEL_d12150eab9f44f64be847b5d54b20426"
          }
        },
        "6d31e3f1b97b48309264d4eb82c7099d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_324674f5002444cea51a259cfcc6d125",
            "placeholder": "​",
            "style": "IPY_MODEL_1cb2ac3c06ad48ce993c916b277e0257",
            "value": "Optimization Progress: 100%"
          }
        },
        "c1a78bb2373b432b8bcd4a9378b88f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c1b0ebc5a48471f91db219dee56a237",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_180abc5e33f04f8284daaa38d03c8029",
            "value": 120
          }
        },
        "243d80deab9749768c4b68c9891488cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c4f076b5ac448b1b9580712350f6b5a",
            "placeholder": "​",
            "style": "IPY_MODEL_2b21c6fe88d24eb8884b9712d566d964",
            "value": " 120/120 [03:39&lt;00:00,  2.26s/pipeline]"
          }
        },
        "d12150eab9f44f64be847b5d54b20426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "324674f5002444cea51a259cfcc6d125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb2ac3c06ad48ce993c916b277e0257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c1b0ebc5a48471f91db219dee56a237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180abc5e33f04f8284daaa38d03c8029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c4f076b5ac448b1b9580712350f6b5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b21c6fe88d24eb8884b9712d566d964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PietroParenti/youtube-comments-classifier/blob/main/SPAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import nltk\n",
        "from IPython.display import IFrame\n",
        "from google.colab import drive\n",
        "from tpot import TPOTClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "DjefF_Sik0iK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "A7VsAcZF5Eod",
        "outputId": "0463495e-7369-43e4-9c9c-0c53301b4b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              COMMENT_ID                              AUTHOR  \\\n",
              "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504                          dharma pal   \n",
              "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj                       Tiza Arellano   \n",
              "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k  Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿   \n",
              "3      z12icv3ysqvlwth2c23eddlykyqut5z1h                       Eric Gonzalez   \n",
              "4      z133stly3kete3tly22petvwdpmghrlli                       Analena López   \n",
              "\n",
              "                         DATE  \\\n",
              "0  2015-05-29T02:30:18.971000   \n",
              "1  2015-05-29T00:14:48.748000   \n",
              "2  2015-05-28T21:00:08.607000   \n",
              "3  2015-05-28T20:47:12.193000   \n",
              "4  2015-05-28T17:08:29.827000   \n",
              "\n",
              "                                             CONTENT  CLASS  \n",
              "0                                         Nice song﻿      0  \n",
              "1                                      I love song ﻿      0  \n",
              "2                                      I love song ﻿      0  \n",
              "3  860,000,000 lets make it first female to reach...      0  \n",
              "4                      shakira is best for worldcup﻿      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a84120d6-41ec-42e2-a462-e02e7c0ca3de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMMENT_ID</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>DATE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>z13lgffb5w3ddx1ul22qy1wxspy5cpkz504</td>\n",
              "      <td>dharma pal</td>\n",
              "      <td>2015-05-29T02:30:18.971000</td>\n",
              "      <td>Nice song﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj</td>\n",
              "      <td>Tiza Arellano</td>\n",
              "      <td>2015-05-29T00:14:48.748000</td>\n",
              "      <td>I love song ﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>z12quxxp2vutflkxv04cihggzt2azl34pms0k</td>\n",
              "      <td>Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿</td>\n",
              "      <td>2015-05-28T21:00:08.607000</td>\n",
              "      <td>I love song ﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>z12icv3ysqvlwth2c23eddlykyqut5z1h</td>\n",
              "      <td>Eric Gonzalez</td>\n",
              "      <td>2015-05-28T20:47:12.193000</td>\n",
              "      <td>860,000,000 lets make it first female to reach...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>z133stly3kete3tly22petvwdpmghrlli</td>\n",
              "      <td>Analena López</td>\n",
              "      <td>2015-05-28T17:08:29.827000</td>\n",
              "      <td>shakira is best for worldcup﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a84120d6-41ec-42e2-a462-e02e7c0ca3de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a84120d6-41ec-42e2-a462-e02e7c0ca3de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a84120d6-41ec-42e2-a462-e02e7c0ca3de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c353acc-f7fa-4ebc-b3f7-c552c38f41da\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c353acc-f7fa-4ebc-b3f7-c552c38f41da')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c353acc-f7fa-4ebc-b3f7-c552c38f41da button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_original\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"COMMENT_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj\",\n          \"z133stly3kete3tly22petvwdpmghrlli\",\n          \"z12quxxp2vutflkxv04cihggzt2azl34pms0k\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUTHOR\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Tiza Arellano\",\n          \"Analena L\\u00f3pez\",\n          \"Pr\\u00ec\\u00f1\\u00e7e\\u015b\\u015b \\u00c2li\\u015b \\u0141\\u00f8v\\u00ea D\\u00f8m\\u00ed\\u00f1\\u00f8 M\\u00e2\\u0111i\\u015b\\u2122 \\ufeff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DATE\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2015-05-29T00:14:48.748000\",\n          \"2015-05-28T17:08:29.827000\",\n          \"2015-05-28T21:00:08.607000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CONTENT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"I love song \\ufeff\",\n          \"shakira is best for worldcup\\ufeff\",\n          \"Nice song\\ufeff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "# Monta Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Percorsi dei file in Drive\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/MachineLearning/SPAM/Youtube05-Shakira.csv',\n",
        "    '/content/drive/MyDrive/MachineLearning/SPAM/Youtube04-Eminem.csv',\n",
        "    '/content/drive/MyDrive/MachineLearning/SPAM/Youtube03-LMFAO.csv',\n",
        "    '/content/drive/MyDrive/MachineLearning/SPAM/Youtube02-KatyPerry.csv',\n",
        "    '/content/drive/MyDrive/MachineLearning/SPAM/Youtube01-Psy.csv'\n",
        "]\n",
        "\n",
        "# Leggi e unisci i CSV\n",
        "dataframes = [pd.read_csv(fp, encoding='utf-8-sig') for fp in file_paths]\n",
        "df_original = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "df_original.loc[df_original.index<5,:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_original\n",
        "\n",
        "\n",
        "##########################\n",
        "# Let's get some info about the dataframe\n",
        "# Showing the number of rows and columns of the DataFrame (i.e., of the data matrix)\n",
        "print(\"Number of rows: \")\n",
        "print(df.shape[0])\n",
        "print() # print an empty line\n",
        "\n",
        "# \\n is carriage return, \"a capo\" in Italian\n",
        "print(\"Number of columns: \")\n",
        "print(df.shape[1])\n",
        "print() # print an empty line\n",
        "\n",
        "print('Column names')\n",
        "# columns are turned into a list to get a cleaner output\n",
        "print(list(df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib3LC7OP7bSj",
        "outputId": "5e6f00e9-0c41-4565-d060-002e80ad33dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: \n",
            "1956\n",
            "\n",
            "Number of columns: \n",
            "5\n",
            "\n",
            "Column names\n",
            "['COMMENT_ID', 'AUTHOR', 'DATE', 'CONTENT', 'CLASS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Looking for missing values i.e., null values (in pandas they are called NaN)\n",
        "for col in ['COMMENT_ID', 'AUTHOR', 'DATE', 'CONTENT', 'CLASS']:\n",
        "    missingValueMask = df[col].isna()\n",
        "    num_missing = missingValueMask.sum()\n",
        "\n",
        "    if num_missing == 0:\n",
        "        print(f'No missing values in column {col}')\n",
        "    else:\n",
        "        print(f'{num_missing} missing values in column {col}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daRaMm5R8M2A",
        "outputId": "18242058-b524-4c56-ae1e-172594628b6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values in column COMMENT_ID\n",
            "No missing values in column AUTHOR\n",
            "245 missing values in column DATE\n",
            "No missing values in column CONTENT\n",
            "No missing values in column CLASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Presence of missing values only in date column. The date column will not be used in analisys, so NA are not removed"
      ],
      "metadata": {
        "id": "SjnPFPa4b7Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruINIKOJgUbV",
        "outputId": "f8cda88f-c69c-4187-fa92-3171961cc3c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMENT_ID    object\n",
            "AUTHOR        object\n",
            "DATE          object\n",
            "CONTENT       object\n",
            "CLASS          int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteggio assoluto\n",
        "print(\"Conteggio osservazioni per classe:\")\n",
        "print(df['CLASS'].value_counts())\n",
        "print()\n",
        "\n",
        "# Percentuale\n",
        "print(\"Percentuale osservazioni per classe:\")\n",
        "print(df['CLASS'].value_counts(normalize=True) * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZWm5CWWcSZI",
        "outputId": "154e9835-7604-4ebe-8b98-df62bfb2e57b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteggio osservazioni per classe:\n",
            "CLASS\n",
            "1    1005\n",
            "0     951\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentuale osservazioni per classe:\n",
            "CLASS\n",
            "1    51.380368\n",
            "0    48.619632\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is unbalanced. To implement the ml algoritm is better to have balanced data.\n",
        "\n",
        "Downsampling:"
      ],
      "metadata": {
        "id": "i2jIqK4ii5Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unbalanced=df\n",
        "\n",
        "\n",
        "def underSample2Min(df, labelName):\n",
        "    ''' The dataset is undersampled so that all label groups will have the same size,\n",
        "        corresponding to the (original) minimal label set.\n",
        "        The parameter labelName is the DataFrmae column hosting the labels'''\n",
        "\n",
        "    vc = df.loc[:,labelName].value_counts() # Counting label frequencies\n",
        "    lab2freq = dict(zip(vc.index.tolist(), vc.values.tolist()))\n",
        "    #print(lab2freq) # if you want to see lab2freq, please uncomment this command\n",
        "    #print(min(lab2freq.values()))\n",
        "    minfreq = min(lab2freq.values())\n",
        "    #print(minfreq)\n",
        "    idxSample=[]\n",
        "    for selectedLabel, actualFreq in lab2freq.items():\n",
        "        selIndexes=df.loc[df.loc[:,labelName]==selectedLabel, :].sample(n=minfreq).index.tolist()\n",
        "        idxSample+=selIndexes\n",
        "    idxSample.sort()\n",
        "    #print(type(idxSample), idxSample)\n",
        "    #print(list(df.index)[:5])\n",
        "\n",
        "    df2 = df.loc[idxSample, :]\n",
        "    #print(len(idxSample), df2.shape);exit()\n",
        "    df2 = df2.reset_index() # otherwise missing index may cause problem\n",
        "    return df2\n",
        "\n",
        "df = underSample2Min(df_unbalanced, 'CLASS')\n",
        "\n",
        "# Let's look again to the category sizes\n",
        "print(\"Conteggio osservazioni per classe:\")\n",
        "print(df['CLASS'].value_counts())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AokqqEzXjBfF",
        "outputId": "6345dcea-ea8a-4e08-d6e7-dcac569eaa2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteggio osservazioni per classe:\n",
            "CLASS\n",
            "0    951\n",
            "1    951\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Splitting the dataset into train and test\n",
        "\n",
        "xAll = df.loc[:,'CONTENT'] # Selecting the title column. It will be used as input feature i.e., the x\n",
        "yAll = df.loc[:,'CLASS'] # Selecting the CategoryID column i.e., the y\n",
        "print('type(xAll)', type(xAll), 'xAll.shape', xAll.shape)\n",
        "print('type(yAll)', type(yAll), 'xAll.shape', yAll.shape)\n",
        "print()\n",
        "\n",
        "# Suddivido xAll e yAll in due sottoinsiemi, rispettivamente di training e test\n",
        "xTrainVec, xTestVec, yTrain, yTest = train_test_split(\n",
        "    xAll, yAll, # the x and y to be partitioned\n",
        "    test_size=0.30, # the test set size will be 30% of the original dataset, i.e. trainini size will be 70%\n",
        "    random_state=0, # random_state is the seed to make random number generation reproducible (and hence the split into train and test)\n",
        "    stratify=yAll # stratify: tries to ensure a proportional distribution of labels among train and test set\n",
        ")\n",
        "\n",
        "# Now I want to inspect the shape\n",
        "varDi = {'xAll':xAll, 'yAll':yAll, 'xTrainVec':xTrainVec, 'xTestVec':xTestVec, 'yTrain':yTrain, 'yTest':yTest}\n",
        "for varName, var in varDi.items(): # return a list of key-value pairs\n",
        "  print(varName, var.shape)\n",
        "# since xAll and xTrainVec are pandas Series (i.e., columns), info about the number of columns is missing because is trivial\n",
        "\n",
        "# xTrain e' una pandas series (semplificando, una colonna del DataFrame),\n",
        "# la trasformo in una lista di stringhe\n",
        "xTrain = list(xTrainVec)\n",
        "xTest = list(xTestVec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCA1ns_FkD3p",
        "outputId": "c847ce39-d356-4670-b80f-fc28cd7666e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(xAll) <class 'pandas.core.series.Series'> xAll.shape (1902,)\n",
            "type(yAll) <class 'pandas.core.series.Series'> xAll.shape (1902,)\n",
            "\n",
            "xAll (1902,)\n",
            "yAll (1902,)\n",
            "xTrainVec (1331,)\n",
            "xTestVec (571,)\n",
            "yTrain (1331,)\n",
            "yTest (571,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prima pipeline"
      ],
      "metadata": {
        "id": "3l9FwPZVkjny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Simple Pipeline\n",
        "# tokenization and stop words filtering is performed using\n",
        "# CountVectorizer built-in functions\n",
        "\n",
        "# Let's build a pipeline for preprocessing and classifying job vacancy titles\n",
        "cp = Pipeline(\n",
        "    [\n",
        "      ('vectorizer', CountVectorizer()),\n",
        "      ('classifier', LogisticRegression() ), # LinearSVC is another classifier you can try\n",
        "    ]\n",
        ")\n",
        "\n",
        "# We collect all the configuration parameters inside a single data structure.\n",
        "# Each parameter is identified by the string pipelineComponentName__ParamName.\n",
        "# The pipeline component name and the param name are separated\n",
        "# by 2 underscore \"_\"\n",
        "clsfParams = {\n",
        "   'classifier__C': 0.001,  # C is equivalent to 1/lambda\n",
        "   'vectorizer__stop_words':'english', # articles are discarded\n",
        "   'vectorizer__ngram_range': (1,1), #only unigrams are considered. (1,2) is for both unigrams and bigrams, (1,3) is for unigrams bigrams and trigrams, ...\n",
        "}\n",
        "\n",
        "# The parameters are set NOW, after pipeline creation\n",
        "# This is strange at the very beginning,\n",
        "# but later you will apreciate it\n",
        "cp.set_params(**clsfParams)\n",
        "cp.fit(xTrain, yTrain)\n",
        "\n",
        "# Performing the prediction\n",
        "yPred=cp.predict(xTest)\n",
        "\n",
        "#Computing the classification report\n",
        "print('Classification report')\n",
        "clasRepSt01 = classification_report(yTest,yPred)\n",
        "print(clasRepSt01)\n",
        "\n",
        "#Computgin accuracy too\n",
        "print('Accuracy')\n",
        "print(accuracy_score(yTest,yPred))\n",
        "\n",
        "# What will be the accuracy, in your opinion?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWmTJ_KYlSRb",
        "outputId": "056b7fb8-f9d7-4b25-e79b-3a9e04d406fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89       286\n",
            "           1       0.97      0.78      0.86       285\n",
            "\n",
            "    accuracy                           0.88       571\n",
            "   macro avg       0.89      0.88      0.88       571\n",
            "weighted avg       0.89      0.88      0.88       571\n",
            "\n",
            "Accuracy\n",
            "0.8774080560420315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# Let's customize (and improve) the preprocessing\n",
        "\n",
        "\n",
        "class BaseWrapper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"class wrapping a sentence processing function so that it can be used in a sklearn.pipeline.Pipeline\"\"\"\n",
        "\n",
        "    def fit(self, x, y=None): #This method is usually overridden in children classes\n",
        "        \"\"\" This method actually does nothing.\n",
        "        It will be overridden by the child classes.\n",
        "        In its children implementations this method will perform all the\n",
        "        setup activities required before calling either the method transform()\n",
        "        or the method predict().\n",
        "        E.g., a machine learning classifier is trained calling the fit() method,\n",
        "        once trained it can be used to classify new elements by calling the method predict()\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def manageSentence(self, sentence): #This method is usually overridden in children classes\n",
        "        \"\"\"Called by transform(). The sentence is expected to be a either a string or a list of words,\n",
        "        this method can return either a string or a list of words\"\"\"\n",
        "        return sentence\n",
        "\n",
        "    def transform(self, listOfSentences):\n",
        "        \"\"\" sentenceList: list of sentences.\n",
        "        Every sentence can be either a string or a list of words\n",
        "        Return a list of lists. Each sentence is preprocessed using the manageSentence() method.\n",
        "        Each child class can override the manageSentence() method to implement a specific preprocessing behavior.\n",
        "        The list of preprocessed documents is returned.\"\"\"\n",
        "        toReturn = []\n",
        "        for sentence in listOfSentences:\n",
        "            processedSentence = self.manageSentence(sentence)\n",
        "            toReturn.append(processedSentence)\n",
        "        return toReturn\n",
        "        # using python list comprehension, the above method can be implemented in a single line:\n",
        "        # return [self.manageSentence(sentence) for sentence in listOfSentences]\n",
        "        # more details https://towardsdatascience.com/python-basics-list-comprehensions-631278f22c40\n",
        "\n",
        "\n",
        "\n",
        "class HTMLAccentsReplacer(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Replace html representations of special letters with the corresponding unicode character.\n",
        "        E.g.  &agrave with à.\n",
        "        Args:\n",
        "           * s(string): the string where the html codes should be replaced  \"\"\"\n",
        "        assert type(sentence)==type('') or type(sentence)==type(u''), \"HTMLAccentsReplacer Assertion Error\" # if the parameter is not the right type, the execution is interrupted. This is useful to catch errors\n",
        "        # sostituita con la versione seguente piu' completa\n",
        "        replacemap={'&Ecirc;': 'Ê', '&raquo;': '»', '&eth;': 'ð', '&divide;': '÷', '&atilde;': 'ã', '&Aelig;':\n",
        "                    'Æ', '&frac34;': '¾', '&nbsp;': ' ', '&Aumbl;': 'Ä', '&Ouml;': 'Ö', '&Egrave;': 'È', '&Icirc;': 'Î',\n",
        "                    '&deg;': '°', '&ocirc;': 'ô', '&Ugrave;': 'Ù', '&ndash;': '–', '&gt;': '>', '&Thorn;': 'Þ',\n",
        "                    '&aring;': 'å', '&frac12;': '½', '&frac14;': '¼', '&Aacute;': 'Á', '&szlig;': 'ß', '&trade;': '™',\n",
        "                    '&igrave;': 'ì', '&aelig;': 'æ', '&times;': '×', '&egrave;': 'è', '&Atilde;': 'Ã', '&Igrave;': 'Ì',\n",
        "                    '&Eth;': 'Ð', '&ucirc;': 'û', '&lsquo;': '‘', '&agrave;': 'à', '&thorn;': 'þ', '&Ucirc;': 'Û',\n",
        "                    '&amp;': '&', '&uuml;': 'ü', '&yuml;': '', '&ecirc;': 'ê', '&laquo;': '«', '&infin;': '∞',\n",
        "                    '&Ograve;': 'Ò', '&oslash;': 'ø', '&yacute;': 'ý', '&plusmn;': '±', '&icirc;': 'î', '&auml;': 'ä',\n",
        "                    '&ouml;': 'ö', '&Ccedil;': 'Ç', '&euml;': 'ë', '&lt;': '<', '&eacute;': 'é', '&ntilde;': 'ñ',\n",
        "                    '&pound;': '£', '&Iuml;': 'Ï', '&Eacute;': 'É', '&Ntilde;': 'Ñ', '&rsquo;': '’', '&euro;': '€',\n",
        "                    '&rdquo;': '”', '&Acirc;': 'Â', '&ccedil;': 'ç', '&Iacute;': 'Í', '&quot;': '\"', '&Aring;': 'Å',\n",
        "                    '&Oslash;': 'Ø', '&Otilde;': 'Õ', '&Uacute;': 'Ú', '&reg;': '®', '&Yacute;': 'Ý', '&iuml;': 'ï',\n",
        "                    '&ugrave;': 'ù', '&alpha;': 'α', '&copy;': '©', '&ldquo;': '“', '&oacute;': 'ó', '&Euml;': 'Ë',\n",
        "                    '&uacute;': 'ú', '&ograve;': 'ò', '&acirc;': 'â', '&aacute;': 'á', '&Agrave;': 'À', '&Oacute;': 'Ó',\n",
        "                    '&Uuml;': 'Ü', '&iacute;': 'í', '&cent;': '¢', '&Ocirc;': 'Ô', '&mdash;': '—', '&otilde;': 'õ',\n",
        "                    '&beta;': 'β'\n",
        "        }\n",
        "        # replacemap where targets are coded using unicode codes\n",
        "        '''\n",
        "        replacemap={u'&Ecirc;': u'\\xca', u'&raquo;': u'\\xbb', u'&eth;': u'\\xf0', u'&divide;': u'\\xf7',\n",
        "                    u'&atilde;': u'\\xe3', u'&Aelig;': u'\\xc6', u'&frac34;': u'\\xbe', u'&nbsp;': u' ',\n",
        "                    u'&Aumbl;': u'\\xc4', u'&Ouml;': u'\\xd6', u'&Egrave;': u'\\xc8', u'&Icirc;': u'\\xce',\n",
        "                    u'&deg;': u'\\xb0', u'&ocirc;': u'\\xf4', u'&Ugrave;': u'\\xd9', u'&ndash;': u'\\u2013',\n",
        "                    u'&gt;': u'>', u'&Thorn;': u'\\xde', u'&aring;': u'\\xe5', u'&frac12;': u'\\xbd',\n",
        "                    u'&frac14;': u'\\xbc', u'&Aacute;': u'\\xc1', u'&szlig;': u'\\xdf', u'&trade;': u'\\u2122',\n",
        "                    u'&igrave;': u'\\xec', u'&aelig;': u'\\xe6', u'&times;': u'\\xd7', u'&egrave;': u'\\xe8',\n",
        "                    u'&Atilde;': u'\\xc3', u'&Igrave;': u'\\xcc', u'&Eth;': u'\\xd0', u'&ucirc;': u'\\xfb',\n",
        "                    u'&lsquo;': u'\\u2018', u'&agrave;': u'\\xe0', u'&thorn;': u'\\xfe', u'&Ucirc;': u'\\xdb',\n",
        "                    u'&amp;': u'&', u'&uuml;': u'\\xfc', u'&yuml;': u'', u'&ecirc;': u'\\xea', u'&laquo;': u'\\xab',\n",
        "                    u'&infin;': u'\\u221e', u'&Ograve;': u'\\xd2', u'&oslash;': u'\\xf8', u'&yacute;': u'\\xfd',\n",
        "                    u'&plusmn;': u'\\xb1', u'&icirc;': u'\\xee', u'&auml;': u'\\xe4', u'&ouml;': u'\\xf6',\n",
        "                    u'&Ccedil;': u'\\xc7', u'&euml;': u'\\xeb', u'&lt;': u'<', u'&eacute;': u'\\xe9',\n",
        "                    u'&ntilde;': u'\\xf1', u'&pound;': u'\\xa3', u'&Iuml;': u'\\xcf', u'&Eacute;': u'\\xc9',\n",
        "                    u'&Ntilde;': u'\\xd1', u'&rsquo;': u'\\u2019', u'&euro;': u'\\u20ac', u'&rdquo;': u'\\u201d',\n",
        "                    u'&Acirc;': u'\\xc2', u'&ccedil;': u'\\xe7', u'&Iacute;': u'\\xcd', u'&quot;': u'\"',\n",
        "                    u'&Aring;': u'\\xc5', u'&Oslash;': u'\\xd8', u'&Otilde;': u'\\xd5', u'&Uacute;': u'\\xda',\n",
        "                    u'&reg;': u'\\xae', u'&Yacute;': u'\\xdd', u'&iuml;': u'\\xef', u'&ugrave;': u'\\xf9',\n",
        "                    u'&alpha;': u'\\u03b1', u'&copy;': u'\\xa9', u'&ldquo;': u'\\u201c', u'&oacute;': u'\\xf3',\n",
        "                    u'&Euml;': u'\\xcb', u'&uacute;': u'\\xfa', u'&ograve;': u'\\xf2', u'&acirc;': u'\\xe2',\n",
        "                    u'&aacute;': u'\\xe1', u'&Agrave;': u'\\xc0', u'&Oacute;': u'\\xd3', u'&Uuml;': u'\\xdc',\n",
        "                    u'&iacute;': u'\\xed', u'&cent;': u'\\xa2', u'&Ocirc;': u'\\xd4', u'&mdash;': u'\\u2014',\n",
        "                    u'&otilde;': u'\\xf5', u'&beta;': u'\\u03b2'}\n",
        "        '''\n",
        "        for before in replacemap:\n",
        "            after=replacemap[before] # getting the string to be replaced\n",
        "            sentence=sentence.replace(before, after)\n",
        "        return sentence\n",
        "\n",
        "'''\n",
        "# Required in python2, no more necessary in python3\n",
        "class Str2Unicode(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Converts raw strings to unicode, to better manage accented letters, money symbols (e.g., pounds)\"\"\"\n",
        "        #print(type(sentence), sentence) # ****** cancellami\n",
        "        # if the parameter is not the right type, the execution is interrupted\n",
        "        assert type(sentence)==type('') or type(sentence)==type(u''), \"Str2Unicode Assertion Error\"\n",
        "        if type(sentence)==type(u''): # Now it should work also with python3\n",
        "            return sentence\n",
        "        elif type(sentence)==type(''):\n",
        "            return sentence.decode('utf-8', errors='strict')  # interpret all raw strings into unicode\n",
        "        else:\n",
        "            return sentence\n",
        "'''\n",
        "\n",
        "class Tokenizer(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"This method turn a single document (i.e., a string) into a list of single words (i.e., tokens).\n",
        "        The parameter \"sentence\" is expected to be a string, this method returns a list of strings whereas each string\n",
        "        is a tokenized word. This method replaces all the punctuation with spaces.\n",
        "        Two or more consecuitve spaces are reduced to a single space.\n",
        "        Then the strin is splitted in substring using the spaces as split markers\"\"\"\n",
        "\n",
        "        if sentence==None:\n",
        "            return[]\n",
        "        # if the parameter is not the right type, the execution is interrupted\n",
        "        assert type(sentence)==type('') or type(sentence)==type(u''), \"Tokenizer Assertion Error\"\n",
        "        punteggiatura=u'!{}[]?\"\",;.:-<>|/\\\\*=+-_% \\n\\t\\r()'+u\"'\" +u'\\u2019'+u'\\u2018' #\\r and \\n can be used as \"new line\"\n",
        "        # Unicode Character 'RIGHT SINGLE QUOTATION MARK' (U+2019)\n",
        "        #\n",
        "        for l in punteggiatura:\n",
        "           #print(s)\n",
        "           sentence=sentence.replace(l,u\" \") #replacing all punctuation characters with spaces\n",
        "\n",
        "        # loop untill all double spaces are removed\n",
        "        while sentence.find(u\"  \")!=-1:\n",
        "            sentence=sentence.replace(u\"  \",u\" \")  #replacing double spaces with a single one\n",
        "        return sentence.split(u' ')   #e.g., \"a b c d\".split(' ')  returns ['a','b','c','d']\n",
        "\n",
        "class LowerCaseReducer(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (each item is a string),\n",
        "        this method returns a list of strings whereas each string is the lower case version of the original word\"\"\"\n",
        "        # preliminary check over the input data type\n",
        "        assert type(sentence)==type([]), \"LowerCaseReducer, Assertion Error\"\n",
        "        # The next line uses a python trick called List Comprehensions.\n",
        "        # More details about List Comprehension on http://www.pythonforbeginners.com/basics/list-comprehensions-in-python\n",
        "        return [w.lower() for w in sentence]\n",
        "        # builds a new list, where each word of the original list is turned into a lower case string\n",
        "\n",
        "\n",
        "class EnglishStopWordsRemover(BaseWrapper):\n",
        "    def getStopWords(self):\n",
        "        \"\"\"This method returns a list of English stop words. Stop words can be added to the list\"\"\"\n",
        "        return [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves',\n",
        "                u'you', u'your', u'yours', u'yourself', u'yourselves',\n",
        "                u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself',\n",
        "                u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves',\n",
        "                u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those',\n",
        "                u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being',\n",
        "                u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing',\n",
        "                u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while',\n",
        "                u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through',\n",
        "                u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out',\n",
        "                u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when',\n",
        "                u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other',\n",
        "                u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very',\n",
        "                u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're',\n",
        "                u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn',\n",
        "                u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n",
        "\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (a list where each item is a string containing a single word),\n",
        "        this method returns the input list where the stop words are removed \"\"\"\n",
        "        assert type(sentence)==type([]) , \"EnglishStopWordsRemover, Assertion Error\"\n",
        "        stopWords = self.getStopWords()\n",
        "        return [w for w in sentence if w not in stopWords]\n",
        "\n",
        "class EnglishStemmer(BaseWrapper):\n",
        "    def __init__(self):\n",
        "        \"\"\"Load the NLTK English stemmer. A stemmer is an algorithm that recues a word to its base form\n",
        "        e.g., \"books\" is reduced to \"book\", 'children' is reduced to 'child'. \"\"\"\n",
        "        self.st = nltk.stem.SnowballStemmer(\"english\") # loading the NLTK stemmer\n",
        "    def  manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (a list where each item is a string containing a single word),\n",
        "        this method returns a list of stemmed words\"\"\"\n",
        "        assert type(sentence)==type([]), \"EnglishStemmer, Assertion Error\"\n",
        "        return [self.st.stem(w) for w in sentence]\n",
        "\n",
        "# Here it is an examle about stemming\n",
        "#es = EnglishStemmer()\n",
        "#wt = Tokenizer()\n",
        "#res=es.transform(wt.transform([\"we are looking for some new cars\", \"having better performances\"]))\n",
        "#print(res)\n",
        "# [[u'we', u'are', u'look', u'for', u'some', u'new', u'car'], [u'have', u'better', u'perform']]\n",
        "\n",
        "\n",
        "class RemoveNumbers(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Sentence is expected to be a list of words (a list where each item is a string containing a single word),\n",
        "        this method returns the input list where the numbers are removed. \"\"\"\n",
        "        assert type(sentence)==type([]), \"RemoveNumbers, Assertion Error\"\n",
        "        return [w for w in sentence if w.isdigit()==False]\n",
        "\n",
        "class RemoveEmptyWords(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Sentence is expected to be a list of words (a list where each item is a string containing a single word),\n",
        "        this method returns the input list where the empty words are removed \"\"\"\n",
        "        assert type(sentence)==type([]), \"RemoveEmptyWords, Assertion Error\"\n",
        "        return [w for w in sentence if not (w==u'' or w=='')]\n",
        "\n",
        "# No more required. Useful for previous versions of CountVectorizer\n",
        "class Bag2Text(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (a list where each item is a string containing a single word),\n",
        "        this method returns a single string obtained joining the words and separing them using the space\"\"\"\n",
        "        assert type(sentence)==type([]), \"Bag2Text, Assertion Error\"\n",
        "        # Next line builds a string by joining with spaces all the elements of sentence\n",
        "        return u' '.join(sentence)\n",
        "\n",
        "def unityFunction(x):\n",
        "  \"\"\"This function returns the same object received as input.\n",
        "  For advanced pythonists: equivalent to lambda x:x \"\"\"\n",
        "  return x"
      ],
      "metadata": {
        "id": "PkXeI6K7nszq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "#\n",
        "\n",
        "# Let's build a pipeline for preprocessing and classifying job vacancy titles\n",
        "cp = Pipeline([\n",
        "   #('Str2Unicode', Str2Unicode()), no more required in Python3\n",
        "   ('HTMLAccentsReplacer', HTMLAccentsReplacer() ),\n",
        "   ('Tokenizer', Tokenizer() ),\n",
        "   ('LowerCaseReducer', LowerCaseReducer() ),\n",
        "   ('StopWordsRemover', EnglishStopWordsRemover() ),\n",
        "   ('Stemmer', EnglishStemmer() ),\n",
        "   ('RemoveNumbers', RemoveNumbers() ),\n",
        "   ('RemoveEmptyWords', RemoveEmptyWords() ),\n",
        "   #('Bag2Text', Bag2Text() ),\n",
        "   ('vectorizer', CountVectorizer()),\n",
        "   ('classifier', LogisticRegression() ), # LinearSVC\n",
        "                           ])\n",
        "\n",
        "# Collecting all the param values in a single data structure.\n",
        "# The parameter keyword should be composed as follows: pipelineComponentName + '__' + paramName.\n",
        "clsfParams = {\n",
        "   'classifier__C': 0.001,\n",
        "   'vectorizer__preprocessor': unityFunction, # since we provided a customized preprocessing pipeline, we turn off the usual preprocessing pipeline\n",
        "   'vectorizer__tokenizer': unityFunction, # Same as above.\n",
        "   'vectorizer__token_pattern': None, # to prevent a warning. This is used in combination with a custom tokenizer\n",
        "   'vectorizer__ngram_range': (1,1),\n",
        "\n",
        "}\n",
        "\n",
        "cp.set_params(**clsfParams)\n",
        "cp.fit(xTrain, yTrain)\n",
        "\n",
        "yPred=cp.predict(xTest)\n",
        "print('Classification report')\n",
        "clasRepSt02 = classification_report(yTest,yPred)\n",
        "print(clasRepSt02)\n",
        "print('Accuracy')\n",
        "print(accuracy_score(yTest,yPred))\n",
        "\n",
        "# What will be the accuracy, in your opinion?\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2znhwtgoXrR",
        "outputId": "34484ae0-5793-4c3d-e06c-58bb55bcc4c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89       286\n",
            "           1       0.97      0.78      0.86       285\n",
            "\n",
            "    accuracy                           0.88       571\n",
            "   macro avg       0.89      0.88      0.87       571\n",
            "weighted avg       0.89      0.88      0.87       571\n",
            "\n",
            "Accuracy\n",
            "0.8756567425569177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid search"
      ],
      "metadata": {
        "id": "1HjNq0xNlA_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Grid Search\n",
        "\n",
        "# Building the pipeline\n",
        "cp = Pipeline([\n",
        "   #('Str2Unicode', Str2Unicode()),\n",
        "   ('HTMLAccentsReplacer', HTMLAccentsReplacer() ),\n",
        "   ('Tokenizer', Tokenizer() ),\n",
        "   ('LowerCaseReducer', LowerCaseReducer() ),\n",
        "   ('StopWordsRemover', EnglishStopWordsRemover() ),\n",
        "   ('Stemmer', EnglishStemmer() ),\n",
        "   ('RemoveNumbers', RemoveNumbers() ),\n",
        "   ('RemoveEmptyWords', RemoveEmptyWords() ),\n",
        "   #('Bag2Text', Bag2Text() ),\n",
        "   ('vectorizer', CountVectorizer()),\n",
        "   ('classifier', LogisticRegression() ),  # LinearSVC\n",
        "                           ])\n",
        "\n",
        "# Setting for each parameter the value space (i.e., the set of values to evaluate)\n",
        "paramSpace = {\n",
        "   'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100], # Values for grid search should be enclosed by []\n",
        "   'classifier__solver': ['liblinear'],\n",
        "   'classifier__class_weight': [None, 'balanced'], # if the classes were imbalanced, we could try this approach\n",
        "   'vectorizer__preprocessor': [unityFunction], # since we provided a customized preprocessing pipeline, we turn off the usual preprocessing pipeline\n",
        "   'vectorizer__tokenizer': [unityFunction], # Same as above.\n",
        "   'vectorizer__token_pattern': [None], # to prevent warnings. This is used in combination with a custom tokenizer\n",
        "   'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],   #\n",
        "   'vectorizer__max_df': [0.7],  # If a term is in more of the 70% of documents, it is too frequent to be discriminative\n",
        "   'vectorizer__min_df': [2, 4], # Minimum number of documents where the term should appear (otherwise it won't be considered in the Vocabulary)\n",
        "} # a python list [] is mandatory even if only one element is in\n",
        "\n",
        "start_time = time.time()\n",
        "# cv=4 k-fold validation, con k=4\n",
        "gs = GridSearchCV(cp, param_grid=paramSpace, scoring='accuracy', cv=4)\n",
        "gs.fit(xTrain,yTrain)\n",
        "# ora mostro il tempo di fine\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(gs.best_params_)\n",
        "print('Scoring result')\n",
        "print(gs.best_score_)\n",
        "\n",
        "# Please, ignore the warnings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQZlg0ULovpH",
        "outputId": "31175f02-4693-4719-ee89-40941b47e362"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 94.28625774383545 seconds ---\n",
            "{'classifier__C': 10, 'classifier__class_weight': None, 'classifier__solver': 'liblinear', 'vectorizer__max_df': 0.7, 'vectorizer__min_df': 2, 'vectorizer__ngram_range': (1, 3), 'vectorizer__preprocessor': <function unityFunction at 0x7e37300e7ce0>, 'vectorizer__token_pattern': None, 'vectorizer__tokenizer': <function unityFunction at 0x7e37300e7ce0>}\n",
            "Scoring result\n",
            "0.9526778284308405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification report della pipeline migliore per gridsearch"
      ],
      "metadata": {
        "id": "fgk_dD6rlFYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "#\n",
        "\n",
        "# Doing classification again, using the best parameters, as selected by Grid Search.\n",
        "# The params used here might be sligthly different w.r.t to the previous grid search output\n",
        "clsfParams = {\n",
        "   'classifier__C': 10,\n",
        "   'classifier__class_weight': None,\n",
        "   'classifier__solver': 'liblinear',\n",
        "   'vectorizer__max_df': 0.7,\n",
        "   'vectorizer__min_df': 4,\n",
        "   'vectorizer__ngram_range': (1, 3),\n",
        "   'vectorizer__preprocessor': unityFunction,\n",
        "   'vectorizer__token_pattern': None,\n",
        "   'vectorizer__tokenizer': unityFunction\n",
        "}\n",
        "cp.set_params(**clsfParams)\n",
        "cp.fit(xTrain, yTrain)\n",
        "yPred=cp.predict(xTest)\n",
        "print('Classification report')\n",
        "print(classification_report(yTest,yPred))\n",
        "print('Accuracy')\n",
        "print(accuracy_score(yTest,yPred))\n",
        "\n",
        "# What will be the accuracy, in your opinion?\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPyklbM2p4p_",
        "outputId": "f3cafc60-7cb7-44f5-8200-4fa5f1a3c9d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       286\n",
            "           1       0.97      0.95      0.96       285\n",
            "\n",
            "    accuracy                           0.96       571\n",
            "   macro avg       0.96      0.96      0.96       571\n",
            "weighted avg       0.96      0.96      0.96       571\n",
            "\n",
            "Accuracy\n",
            "0.9614711033274956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################\n",
        "# Installing the library\n",
        "# The tpot last release has some bugs, installing the previous version\n",
        "! pip install tpot==0.12.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwWk4C77tQkN",
        "outputId": "34d9ed76-b2f7-45d2-b14d-8f8f1ba4b983"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tpot==0.12.2\n",
            "  Downloading TPOT-0.12.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from tpot==0.12.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from tpot==0.12.2) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from tpot==0.12.2) (1.6.1)\n",
            "Collecting deap>=1.2 (from tpot==0.12.2)\n",
            "  Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting update-checker>=0.16 (from tpot==0.12.2)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from tpot==0.12.2) (4.67.1)\n",
            "Collecting stopit>=1.1.1 (from tpot==0.12.2)\n",
            "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from tpot==0.12.2) (2.2.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from tpot==0.12.2) (1.4.2)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tpot==0.12.2) (2.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->tpot==0.12.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->tpot==0.12.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->tpot==0.12.2) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.1->tpot==0.12.2) (3.6.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from update-checker>=0.16->tpot==0.12.2) (2.32.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost>=1.1.0->tpot==0.12.2) (2.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot==0.12.2) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot==0.12.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot==0.12.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot==0.12.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot==0.12.2) (2025.4.26)\n",
            "Downloading TPOT-0.12.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11938 sha256=3c0c3295a456eb4a9855521dd7d44fa9839962cca6f327710b786c8cb238ba3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/77/2d/adbc56bc4db95ad80c6d4e71cd69e2d9d122174904342e3f7f\n",
            "Successfully built stopit\n",
            "Installing collected packages: stopit, deap, update-checker, tpot\n",
            "Successfully installed deap-1.4.3 stopit-1.1.2 tpot-0.12.2 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Creating the Document Term Matrix from xTrain and xTest\n",
        "\n",
        "cv = CountVectorizer(\n",
        "    ngram_range = (1, 3), # Those values were identified as optimal from a previous notebook\n",
        "    min_df = 4,\n",
        "    max_df = 0.7\n",
        ")\n",
        "xTrainDtm = cv.fit_transform(xTrain)\n",
        "xTestDtm = cv.transform(xTest)"
      ],
      "metadata": {
        "id": "nSvdXVnPugxi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tpot import TPOTClassifier\n",
        "\n",
        "tpot = TPOTClassifier(\n",
        "    generations=5,\n",
        "    population_size=20,\n",
        "    verbosity=2,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    config_dict='TPOT sparse',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tpot.fit(xTrainDtm, yTrain)\n",
        "\n",
        "tpot.export('best_pipeline.py')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642,
          "referenced_widgets": [
            "09dc734eaec44468a4b239c1da5d7754",
            "6d31e3f1b97b48309264d4eb82c7099d",
            "c1a78bb2373b432b8bcd4a9378b88f7e",
            "243d80deab9749768c4b68c9891488cd",
            "d12150eab9f44f64be847b5d54b20426",
            "324674f5002444cea51a259cfcc6d125",
            "1cb2ac3c06ad48ce993c916b277e0257",
            "2c1b0ebc5a48471f91db219dee56a237",
            "180abc5e33f04f8284daaa38d03c8029",
            "6c4f076b5ac448b1b9580712350f6b5a",
            "2b21c6fe88d24eb8884b9712d566d964"
          ]
        },
        "id": "1qGSF42G7hUV",
        "outputId": "fb56b8c4-2f18-462a-8551-64b4d3081d9a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_classifier\n",
            "is_classifier\n",
            "is_regressor\n",
            "is_classifier\n",
            "is_regressor\n",
            "is_classifier\n",
            "is_regressor\n",
            "is_classifier\n",
            "is_regressor\n",
            "is_classifier\n",
            "is_regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1230: FutureWarning: passing a class to None is deprecated and will be removed in 1.8. Use an instance of the class instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1270: FutureWarning: passing a class to None is deprecated and will be removed in 1.8. Use an instance of the class instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_classifier\n",
            "is_classifier\n",
            "is_classifier\n",
            "is_classifier\n",
            "is_classifier\n",
            "is_classifier\n",
            "is_regressor\n",
            "is_classifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Version 0.12.2 of tpot is outdated. Version 1.0.0 was released Wednesday February 26, 2025.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09dc734eaec44468a4b239c1da5d7754"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generation 1 - Current best internal CV score: 0.9414024634114928\n",
            "\n",
            "Generation 2 - Current best internal CV score: 0.9428988808221314\n",
            "\n",
            "Generation 3 - Current best internal CV score: 0.9459069679159972\n",
            "\n",
            "Generation 4 - Current best internal CV score: 0.9459069679159972\n",
            "\n",
            "Generation 5 - Current best internal CV score: 0.9459069679159972\n",
            "\n",
            "Best pipeline: LinearSVC(input_matrix, C=0.5, dual=True, loss=hinge, penalty=l2, tol=0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat best_pipeline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvV4GA73wbAk",
        "outputId": "0019e25a-331f-40e4-fd88-3b3893655133"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.svm import LinearSVC\n",
            "\n",
            "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
            "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
            "features = tpot_data.drop('target', axis=1)\n",
            "training_features, testing_features, training_target, testing_target = \\\n",
            "            train_test_split(features, tpot_data['target'], random_state=42)\n",
            "\n",
            "# Average CV score on the training set was: 0.9459069679159972\n",
            "exported_pipeline = LinearSVC(C=0.5, dual=True, loss=\"hinge\", penalty=\"l2\", tol=0.1)\n",
            "# Fix random state in exported estimator\n",
            "if hasattr(exported_pipeline, 'random_state'):\n",
            "    setattr(exported_pipeline, 'random_state', 42)\n",
            "\n",
            "exported_pipeline.fit(training_features, training_target)\n",
            "results = exported_pipeline.predict(testing_features)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
        "\n",
        "\n",
        "# Average CV score on the training set was: 0.9459069679159972\n",
        "exported_pipeline = LinearSVC(C=0.5, dual=True, loss=\"hinge\", penalty=\"l2\", tol=0.1)\n",
        "# Fix random state in exported estimator\n",
        "if hasattr(exported_pipeline, 'random_state'):\n",
        "    setattr(exported_pipeline, 'random_state', 42)\n",
        "\n",
        "exported_pipeline.fit(xTrainDtm, yTrain)\n",
        "results = exported_pipeline.predict(xTestDtm)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(yTest, yPred))\n",
        "print(\"Accuracy:\")\n",
        "print(accuracy_score(yTest, yPred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTu6ppDVwa5D",
        "outputId": "c447140c-df8e-45e7-93de-d8d24ab75a33"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94       286\n",
            "           1       0.96      0.91      0.93       285\n",
            "\n",
            "    accuracy                           0.94       571\n",
            "   macro avg       0.94      0.94      0.94       571\n",
            "weighted avg       0.94      0.94      0.94       571\n",
            "\n",
            "Accuracy:\n",
            "0.9352014010507881\n"
          ]
        }
      ]
    }
  ]
}